{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\BART\\Bart\\coin_data\\coin_Aave.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_BinanceCoin.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Bitcoin.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Cardano.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_ChainLink.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Cosmos.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_CryptocomCoin.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Dogecoin.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_EOS.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Ethereum.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Iota.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Litecoin.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Monero.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_NEM.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Polkadot.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Solana.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Stellar.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Tether.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Tron.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_Uniswap.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_USDCoin.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_WrappedBitcoin.csv\n",
      "D:\\BART\\Bart\\coin_data\\coin_XRP.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('D:\\BART\\Bart\\coin_data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file:\n",
      "SNo\n",
      "Name\n",
      "Symbol\n",
      "Date\n",
      "High\n",
      "Low\n",
      "Open\n",
      "Close\n",
      "Volume\n",
      "Marketcap\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = \"D:\\BART\\Bart\\coin_data\\coin_Dogecoin.csv\"\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Read the header row\n",
    "    header = next(csv_reader)\n",
    "    \n",
    "    # Print the column names\n",
    "    print(\"Columns in the CSV file:\")\n",
    "    for column in header:\n",
    "        print(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Aave 275\n",
      "1 BinanceCoin 1442\n",
      "2 Bitcoin 2991\n",
      "3 Cardano 1374\n",
      "4 ChainLink 1385\n",
      "5 Cosmos 845\n",
      "6 CryptocomCoin 935\n",
      "7 Dogecoin 2760\n",
      "8 EOS 1466\n",
      "9 Ethereum 2160\n",
      "10 Iota 1484\n",
      "11 Litecoin 2991\n",
      "12 Monero 2602\n",
      "13 NEM 2288\n",
      "14 Polkadot 320\n",
      "15 Solana 452\n",
      "16 Stellar 2527\n",
      "17 Tether 2318\n",
      "18 Tron 1392\n",
      "19 Uniswap 292\n",
      "20 USDCoin 1002\n",
      "21 WrappedBitcoin 888\n",
      "22 XRP 2893\n",
      "Coin amount:  23 .\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m coinNum, Slength, info \u001b[38;5;241m=\u001b[39m read_data ()\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoin amount: \u001b[39m\u001b[38;5;124m\"\u001b[39m, coinNum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999 #Outputs more colums for dataframes\n",
    "\n",
    "base = \"D:\\BART\\Bart\\coin_data\"\n",
    "datahistory = 60 #Amount of days for data history to use\n",
    "\n",
    "def coincount(data_drt): # counts amount of coin files within the given directory\n",
    "\n",
    "    coin__Count = 0\n",
    "    for cryptofile in os.listdir(data_drt):\n",
    "        if cryptofile.endswith(\".csv\"):\n",
    "            coin__Count += 1\n",
    "    return coin__Count\n",
    "\n",
    "\n",
    "def get_max_min_data_lengths(data_drt):\n",
    "    #It finds min and max lengths of the data coin files.\n",
    "    lengthmax = 0\n",
    "    lengthmin = float(\"inf\")  #Actiavtes lengthmin to be infinity\n",
    "    for cryptofile in os.listdir(data_drt):\n",
    "        if cryptofile.endswith(\".csv\"):\n",
    "            fD = pd.read_csv(data_drt + \"/\" + cryptofile, parse_dates=['Date'])\n",
    "            lengthdata = fD.shape[0]\n",
    "            lengthmax = max(lengthmax, lengthdata)\n",
    "            lengthmin = min(lengthmin, lengthdata)\n",
    "    return lengthmax,lengthmin\n",
    "\n",
    "\n",
    "def read_process_coin_data(data_drt, indexCoin):\n",
    "    # reads and processes a specific coin\n",
    "    cryptofile = os.listdir(data_drt)[indexCoin]\n",
    "    fD = pd.read_csv(data_drt + \"/\" + cryptofile, parse_dates=['Date'])\n",
    "    symbolCoin = cryptofile[5:-4]\n",
    "    lengthdata = fD.shape[0]\n",
    "    pricesclosing = fD['closed'].values\n",
    "    return symbolCoin, lengthdata, pricesclosing\n",
    "\n",
    "\n",
    "def read_data(data_drt, datahistory):\n",
    "    # reads and processes the cryptocurrency data\n",
    "    coinNum = coin__Count(data_drt)\n",
    "    maxlengthdata = get_max_min_data_lengths(data_drt)  #length_min discarded\n",
    "    pricesclosingdata = np.zeros((coinNum, maxlengthdata))\n",
    "    coinlengthsdata = np.zeros(coinNum, dtype=int)\n",
    "\n",
    "\n",
    "    for indexCoin in range(coinNum):\n",
    "        symbolCoin, lengthdata, pricesclosing = read_process_coin_data(data_drt, indexCoin)\n",
    "        print(indexCoin, symbolCoin, lengthdata)\n",
    "        priceslosingdata[indexCoin, 0:lengthdata] = pricesclosing\n",
    "        coinlengthsdata[indexCoin] = lengthdata\n",
    "\n",
    "\n",
    "def read_data (): # Reading and processing all data of coins\n",
    "\n",
    "    coinNum = 0\n",
    "    for name in os.listdir(base):\n",
    "        coinNum += 1 # counts the amount of files with coins\n",
    "\n",
    "    lengthmax, lengthmin = 0, 1000000 # intiating a big value\n",
    "    for name in os.listdir(base):\n",
    "        fD = pd.read_csv(base + \"/\" + name, parse_dates=['Date'])\n",
    "        thelength = fD.shape[0]\n",
    "        if lengthmax < thelength:\n",
    "            lengthmax = thelength\n",
    "        if lengthmin > thelength:\n",
    "            lengthmin = thelength\n",
    "\n",
    "\n",
    "    info = np.zeros ((coinNum, lengthmax)) #Activates arrays to keep coins data\n",
    "    Slength = np.zeros(coinNum, dtype = int)\n",
    "    i = 0\n",
    "    for name in os.listdir(base):\n",
    "        coinSymb = name[5:-4] #Extracting the symbol of the coin from the file name.\n",
    "        fD = pd.read_csv(base + \"/\" + name, parse_dates=['Date'])\n",
    "        thelength = fD.shape[0]\n",
    "\n",
    "        #Storing coin info.\n",
    "        Slength[i] = thelength\n",
    "        print (i, coinSymb, thelength)\n",
    "\n",
    "        info[i, 0:thelength] = fD['Close'].values\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    return coinNum, Slength, info\n",
    "\n",
    "coinNum, Slength, info = read_data ()\n",
    "print (\"Coin amount: \", coinNum, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scale(info, Slength):\n",
    "\n",
    "    coinNum = info.shape[0] #More cleaner name for the variable.\n",
    "    shift_info = np.zeros(coinNum)\n",
    "    factor_scale = np.zeros(coinNum)\n",
    "    #^^^ shift_info and factor_scale have descriptive name.\n",
    "\n",
    "    for i in range (coinNum):\n",
    "        valMax = info[i,:Slength[i]].max()\n",
    "        valMin = info[i, :Slength[i]].min()\n",
    "        #^^^ Clearing calculation ^^^\n",
    "        shift_info[i] = valMin #This stores the info of shift value of the info.\n",
    "        factor_scale[i] = valMax - valMin #Calculating the factor scale.\n",
    "\n",
    "        if factor_scale[i] == 0:\n",
    "            raise ValueError(\"Division by zero encountered during scaling.\")\n",
    "\n",
    "        info[i,0:Slength[i]] = (info[i,0:Slength[i]]-shift_info[i])/factor_scale[i]\n",
    "    return (shift_info, factor_scale) #Scaling the info and scale factor\n",
    "\n",
    "shift_info, factor_scale = data_scale (info, Slength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately 3514 sequences for validation.\n",
      "Approximately 2878 sequences for testing.\n",
      "Approximately 30345 sequences for training.\n"
     ]
    }
   ],
   "source": [
    "def sequence(info, Slength, begin, finish, datahistory):\n",
    "    assert len(info) == len(Slength), \"Unmatched data length.\"\n",
    "\n",
    "    # Initialize blank lists to keep targets and sequences\n",
    "    A = []\n",
    "    B = []\n",
    "\n",
    "    # Iterate over the specified range of coins\n",
    "    for j in range(begin, finish):\n",
    "        for i in range(datahistory, Slength[j]):\n",
    "            # Append input sequence and its compatible value target\n",
    "            A.append(info[j, i - datahistory:i])\n",
    "            B.append(info[j, i])\n",
    "\n",
    "    X = np.array(A)[:, :, np.newaxis] # Converting lists to numpy arrays and reshape for LSTM input\n",
    "    y = np.array(B)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# number of days for data history to use ie 15 days\n",
    "datahistory = 15\n",
    "\n",
    "# Creating the validation and training, and test sequences\n",
    "X_val, Y_val = sequence(info, Slength, 18, 22, datahistory)\n",
    "print(\"Approximately\", Y_val.shape[0], \"sequences for validation.\")\n",
    "\n",
    "X_test, Y_test = sequence(info, Slength, 22, 23, datahistory)\n",
    "print(\"Approximately\", Y_test.shape[0], \"sequences for testing.\")\n",
    "\n",
    "X_train, Y_train = sequence(info, Slength, 0, 18, datahistory)\n",
    "print(\"Approximately\", Y_train.shape[0], \"sequences for training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LSTMModel:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.W_f = np.random.randn(hidden_size + input_size, hidden_size)\n",
    "        self.W_i = np.random.randn(hidden_size + input_size, hidden_size)\n",
    "        self.W_c = np.random.randn(hidden_size + input_size, hidden_size)\n",
    "        self.W_o = np.random.randn(hidden_size + input_size, hidden_size)\n",
    "        self.W_y = np.random.randn(hidden_size, output_size)\n",
    "        self.b_f = np.zeros((1, hidden_size))\n",
    "        self.b_i = np.zeros((1, hidden_size))\n",
    "        self.b_c = np.zeros((1, hidden_size))\n",
    "        self.b_o = np.zeros((1, hidden_size))\n",
    "        self.b_y = np.zeros((1, output_size))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h_prev = np.zeros((1, self.hidden_size))\n",
    "        c_prev = np.zeros((1, self.hidden_size))\n",
    "        for t in range(len(inputs)):\n",
    "            x_t = inputs[t].reshape((1, self.input_size))\n",
    "            concat = np.hstack((h_prev, x_t))\n",
    "            f = self.sigmoid(np.dot(concat, self.W_f) + self.b_f)\n",
    "            i = self.sigmoid(np.dot(concat, self.W_i) + self.b_i)\n",
    "            c_bar = self.tanh(np.dot(concat, self.W_c) + self.b_c)\n",
    "            c = f * c_prev + i * c_bar\n",
    "            o = self.sigmoid(np.dot(concat, self.W_o) + self.b_o)\n",
    "            h = o * self.tanh(c)\n",
    "            h_prev, c_prev = h, c\n",
    "        y = np.dot(h, self.W_y) + self.b_y\n",
    "        return y\n",
    "\n",
    "def lstm_model(data_history):\n",
    "    input_size = 1\n",
    "    hidden_size = 130\n",
    "    output_size = 1\n",
    "    model = LSTMModel(input_size, hidden_size, output_size)\n",
    "    return model\n",
    "\n",
    "data_history = 15  # number of past observations used\n",
    "model_lstm = lstm_model(data_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 22.914842464640405, Validation Loss: 31.294857864738407\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_train[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m32\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape input data to match the model's input shape\u001b[39;00m\n\u001b[0;32m      7\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m Y_train[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m32\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_lstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((preds \u001b[38;5;241m-\u001b[39m Y_batch) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Mean squared error loss\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Backpropagation (not implemented in this simplified example)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Update weights and biases (not implemented in this simplified example)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 32\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     30\u001b[0m concat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((h_prev, x_t))\n\u001b[0;32m     31\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(np\u001b[38;5;241m.\u001b[39mdot(concat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_f) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_f)\n\u001b[1;32m---> 32\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_i)\n\u001b[0;32m     33\u001b[0m c_bar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh(np\u001b[38;5;241m.\u001b[39mdot(concat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_c) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_c)\n\u001b[0;32m     34\u001b[0m c \u001b[38;5;241m=\u001b[39m f \u001b[38;5;241m*\u001b[39m c_prev \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m c_bar\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model training process\n",
    "training_history = []\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, len(X_train), 32):\n",
    "        X_batch = X_train[i:i+32].reshape(-1, 1)  # Reshape input data to match the model's input shape\n",
    "        Y_batch = Y_train[i:i+32]\n",
    "        preds = model_lstm.forward(X_batch)\n",
    "        loss = np.mean((preds - Y_batch) ** 2)  # Mean squared error loss\n",
    "        # Backpropagation (not implemented in this simplified example)\n",
    "        # Update weights and biases (not implemented in this simplified example)\n",
    "        epoch_loss += loss\n",
    "    epoch_loss /= len(X_train) / 32  # Calculate average loss per batch\n",
    "    # Evaluation on validation set\n",
    "    val_preds = model_lstm.forward(X_val.reshape(-1, 1))  # Reshape validation data as well\n",
    "    val_loss = np.mean((val_preds - Y_val) ** 2)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {epoch_loss}, Validation Loss: {val_loss}\")\n",
    "    training_history.append((epoch_loss, val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def stats_reveal (training):\n",
    "    #Plotting the validation and training curves of loss.\n",
    "    plt.plot(training.history['loss'])\n",
    "    plt.plot(training.history['val_loss'])\n",
    "\n",
    "\n",
    "    #Setting the graph labels and tilte.\n",
    "    plt.title(\"Model\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss Prediction\")\n",
    "    plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "\n",
    "    #Outputs the graph.\n",
    "    plt.show()\n",
    "\n",
    "#Summons the function to get a visualization on the curves loss.\n",
    "stats_reveal (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate the model's predictions on the test dataset\n",
    "prognosis = model_lstm.predict(X_test)\n",
    "\n",
    "plt.title(\"Model's prediction vs real prices\")\n",
    "\n",
    "# calculating the (RMSE) to determine accuracy of prediction\n",
    "\n",
    "rmse = np.sqrt(np.mean(((prognosis - Y_test) ** 2)))\n",
    "print(\"RSME: \", rmse)\n",
    "\n",
    "#Plot : prediction data.\n",
    "plt.plot(prognosis*factor_scale[20] + shift_info[20])\n",
    "\n",
    "#Plots : real data.\n",
    "plt.plot(Y_test*factor_scale[20] + shift_info[20])\n",
    "\n",
    "#Output graph\n",
    "plt.legend([\"Predictions\",\"Real data\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
